# ğŸ¬ Superstore SQL Business Analysis

## ğŸ“Œ Project Overview

This project performs **end-to-end SQL-driven business analysis** on the *Sample â€“ Superstore* dataset. The goal is to identify **profitability drivers, loss-making areas, and actionable business insights** that management can use to improve performance.

This is a **recruiter-focused project** showcasing SQL skills, business thinking, and structured analysis.

---

## ğŸ¯ Business Problem

Retail company wants to understand:

* Which **regions, states, and categories** generate profit
* Which **products and discounts** cause losses
* Who are the **most valuable customers**
* How **discounting impacts profitability**

---

## ğŸ“Š Dataset Description

**Dataset:** Sample â€“ Superstore (Kaggle)
# Superstore â€” SQL & Data Analysis

## Overview

This repository contains a practical, intermediate-level analysis of the "Sample â€” Superstore" dataset. The goal is to show end-to-end work: clean the data, load it into a simple analysis-ready format, run SQL-driven analysis, and produce concise business insights and recommendations. The project is written in a clear, human tone so it reads naturally for recruiters and hiring managers.

Source data comes from Kaggle: https://www.kaggle.com/datasets/vivek468/superstore-dataset-final

Author: Abhinav Verma â€” https://github.com/Abhinav-TheAnalyst / https://www.linkedin.com/in/abhinav-theanalyst/

---

## What you'll find here

- `data/raw/Superstore.csv` â€” original dataset (not committed here)
- `data/processed/superstore_cleaned.csv` â€” cleaned, analysis-ready CSV (generated by the script)
- `scripts/clean_data.py` â€” lightweight Python script (pandas) to clean and export the dataset
- `sql/` â€” collection of SQL queries used for the analysis, organized as step-by-step scripts
- `sql/table_schema.sql` â€” suggested table schema for loading into a relational DB
- `reports/executive_summary.md` â€” short, recruiter-friendly summary and recommendations
- `dashboard/README.md` â€” quick notes on building a dashboard (Power BI / Tableau)
- `requirements.txt` â€” minimal Python deps
- `.gitignore` â€” sensible ignores for this project

---

## Quick start (PowerShell)

1) Create a Python environment and install requirements:

```powershell
python -m venv .venv; .\.venv\Scripts\Activate.ps1
pip install -r requirements.txt
```

2) Place the original `Superstore.csv` in `data/raw/`.

3) Run the cleaning script to produce `data/processed/superstore_cleaned.csv`:

```powershell
python scripts\clean_data.py --input "data/raw/Superstore.csv" --output "data/processed/superstore_cleaned.csv"
```

4) Load the cleaned CSV into your RDBMS of choice (Postgres/MySQL/SQLite) or run the SQL files directly against a local SQLite DB after importing the CSV.

---

## Recommended workflow

1. Clean and standardize data using `scripts/clean_data.py`.
2. Load the cleaned CSV into a database (or use pandas / DuckDB for analysis).
3. Run the SQL scripts in `sql/` in order (01 â†’ 07) to reproduce the analysis.
4. Use `reports/executive_summary.md` for the top-level talking points for interviews or the hiring manager.

